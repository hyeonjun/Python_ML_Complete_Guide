{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TopicModeling.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPg5cpbydne6blmPDSYkptm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 토픽 모델링\n",
        "\n",
        "* 문서 집합에 숨어있는 주제를 찾아내는 것.\n",
        "* 머신러닝 기반의 토픽 모델은 숨겨진 주제를 효과적으로 표현할 수 있는 중심 단어를 함축적으로 추출\n",
        "* LSA(Latent Semantic Analysis), LDA(Latent Dirchlet Allocation) 기법\n",
        "\n"
      ],
      "metadata": {
        "id": "icMqZVtZ3Va2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCK7DwtM3Nzn",
        "outputId": "3116e6a3-8bf9-41e1-88db-16f8b7e8f3cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CountVectorizer Shape: (7862, 1000)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "# 모토사이클, 야구, 그래픽스, 윈도우즈, 중동, 기독교, 의학, 우주 주제를 추출. \n",
        "cats = ['rec.motorcycles', 'rec.sport.baseball', 'comp.graphics', 'comp.windows.x',\n",
        "        'talk.politics.mideast', 'soc.religion.christian', 'sci.electronics', 'sci.med']\n",
        "\n",
        "# 위에서 cats 변수로 기재된 category만 추출. featch_20newsgroups( )의 categories에 cats 입력\n",
        "news_df= fetch_20newsgroups(subset='all',remove=('headers', 'footers', 'quotes'), \n",
        "                            categories=cats, random_state=0)\n",
        "\n",
        "#LDA 는 Count기반의 Vectorizer만 적용합니다.  \n",
        "count_vect = CountVectorizer(max_df=0.95, max_features=1000, min_df=2, stop_words='english', ngram_range=(1,2))\n",
        "feat_vect = count_vect.fit_transform(news_df.data)\n",
        "print('CountVectorizer Shape:', feat_vect.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CountVectorizer 객체 변수인 feat_vect 모두 7862개의 문서가 1000개의 피처로 구성된 행렬 데이터이다. 이렇게 피처 벡터화된 데이터 세트를 기반으로 LDA 토픽 모델을 수행.\n",
        "\n",
        "토픽의 개수는 위의 뉴스 그룹에서 추출한 주제와 동일한 8개로 정한다. LatentDirichletAllocation 클래스의 n_components 파라미터를 이용해 이 토픽 개수를 조정한다."
      ],
      "metadata": {
        "id": "76SL1fO85UAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lda = LatentDirichletAllocation(n_components=8, random_state=0)\n",
        "lda.fit(feat_vect)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvmilWio5otX",
        "outputId": "7d62178d-5594-4981-de5c-82935dc41129"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LatentDirichletAllocation(n_components=8, random_state=0)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LatentDirichletAllocation.fit(데이터 세트)를 수행하면 LatentDirichletAllocation 객체는 components_ 속성값을 가지게 된다. components_는 개별 토픽별로 각 word 피처가 얼마나 많이 그 토픽에 할당됐는지에 대한 수치를 가지고 있다. 높은 값일수록 해당 word 피처는 그 토픽의 중심 word가 된다."
      ],
      "metadata": {
        "id": "re5pN2DN5xLe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(lda.components_.shape)\n",
        "lda.components_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lm9tNeU6Kme",
        "outputId": "501f0b5d-0a40-4525-f153-a028c0dc83d0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8, 1000)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.60992018e+01, 1.35626798e+02, 2.15751867e+01, ...,\n",
              "        3.02911688e+01, 8.66830093e+01, 6.79285199e+01],\n",
              "       [1.25199920e-01, 1.44401815e+01, 1.25045596e-01, ...,\n",
              "        1.81506995e+02, 1.25097844e-01, 9.39593286e+01],\n",
              "       [3.34762663e+02, 1.25176265e-01, 1.46743299e+02, ...,\n",
              "        1.25105772e-01, 3.63689741e+01, 1.25025218e-01],\n",
              "       ...,\n",
              "       [3.60204965e+01, 2.08640688e+01, 4.29606813e+00, ...,\n",
              "        1.45056650e+01, 8.33854413e+00, 1.55690009e+01],\n",
              "       [1.25128711e-01, 1.25247756e-01, 1.25005143e-01, ...,\n",
              "        9.17278769e+01, 1.25177668e-01, 3.74575887e+01],\n",
              "       [5.49258690e+01, 4.47009532e+00, 9.88524814e+00, ...,\n",
              "        4.87048440e+01, 1.25034678e-01, 1.25074632e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "components_는 array[8, 1000]으로 구성되어 있다. 8개의 토픽별로 1000개의 word 피처가 해당 토픽별로 연관도 값을 가지고 있다. 즉, components_ array의 0번째 row, 10번째 col에 있는 값은 Topic #0에 대해서 피처 벡터화된 행렬에서 10번째 칼럼에 해당하는 피처가 Topic #0에 연관되는 수치 값을 가지고 있다. \n",
        "\n",
        "#### lda_model.components_ 값만으로는 각 토픽별 word 연관도를 보기가 어려우니 display_topics() 함수를 만들어 각 토픽별로 연고나도가 높은 순으로 Word를 나열."
      ],
      "metadata": {
        "id": "MxQ93D0h6Ulw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_topics(model, feature_names, no_top_words):\n",
        "    for topic_index, topic in enumerate(model.components_):\n",
        "        print('Topic #',topic_index)\n",
        "\n",
        "        # components_ array에서 가장 값이 큰 순으로 정렬했을 때, 그 값의 array index를 반환. \n",
        "        topic_word_indexes = topic.argsort()[::-1]\n",
        "        top_indexes=topic_word_indexes[:no_top_words]\n",
        "        \n",
        "        # top_indexes대상인 index별로 feature_names에 해당하는 word feature 추출 후 join으로 concat\n",
        "        feature_concat = ' '.join([feature_names[i] for i in top_indexes])                \n",
        "        print(feature_concat)\n",
        "\n",
        "# CountVectorizer객체내의 전체 word들의 명칭을 get_features_names( )를 통해 추출\n",
        "feature_names = count_vect.get_feature_names()\n",
        "\n",
        "# Topic별 가장 연관도가 높은 word를 15개만 추출\n",
        "display_topics(lda, feature_names, 15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWBxzbDi7D6u",
        "outputId": "877c2513-eb70-4900-f419-acf4413d61ac"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic # 0\n",
            "year 10 game medical health team 12 20 disease cancer 1993 games years patients good\n",
            "Topic # 1\n",
            "don just like know people said think time ve didn right going say ll way\n",
            "Topic # 2\n",
            "image file jpeg program gif images output format files color entry 00 use bit 03\n",
            "Topic # 3\n",
            "like know don think use does just good time book read information people used post\n",
            "Topic # 4\n",
            "armenian israel armenians jews turkish people israeli jewish government war dos dos turkey arab armenia 000\n",
            "Topic # 5\n",
            "edu com available graphics ftp data pub motif mail widget software mit information version sun\n",
            "Topic # 6\n",
            "god people jesus church believe christ does christian say think christians bible faith sin life\n",
            "Topic # 7\n",
            "use dos thanks windows using window does display help like problem server need know run\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    }
  ]
}