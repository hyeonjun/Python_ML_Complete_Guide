{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fetch_20NewsGroups.ipynb",
      "provenance": [],
      "mount_file_id": "1-xphdKDRnwoVvFLINfEDEQWbokp3ssfU",
      "authorship_tag": "ABX9TyPk0y7b7gkLiKsyYDlBx+iE"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 20 뉴스그룹 분류\n",
        "\n",
        "* 사이킷런의 fetch_20newsgroups() API를 이용해 뉴스그룹의 분류를 수행\n",
        "* 텍스트를 피처 벡터화 -> 희소 행렬 -> 분류 알고리즘 => 로지스틱 회귀, 선형 서포트 벡터 머신, 나이브 베이즈 등\n",
        "\n",
        "### 텍스트 정규화\n",
        "* fetch_20newsgroups()는 인터넷에서 로컬 컴퓨터로 데이터를 먼저 내려받은 후에 메모리로 데이터를 로딩함."
      ],
      "metadata": {
        "id": "rHFtRv1etoEj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zEsMTx_Xs9FC"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "news_data = fetch_20newsgroups(subset='all', random_state=156)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(news_data.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMGFeEH8vEza",
        "outputId": "beaad04b-11ba-43a8-b8e9-245e89f78ad5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "fetch_20newsgroups() API 역시 load_xxx() API와 유사한 Key 값을 가지고 있다. filenames 라는 key 이름이 눈에 띄는데, 이는 fetch_20newsgroups() API가 인터넷에 내려받아 로컬 컴퓨터에 저장하는 디렉터리와 파일명을 지칭한다."
      ],
      "metadata": {
        "id": "ZtXvwvQHvwng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# target 클래스 값 확인\n",
        "import pandas as pd\n",
        "\n",
        "print('target 클래스의 값과 분포도 \\n',pd.Series(news_data.target).value_counts().sort_index())\n",
        "print('target 클래스의 이름들 \\n',news_data.target_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llCeQbtWwPwR",
        "outputId": "924f9097-5494-481a-db89-93ab6018c27c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target 클래스의 값과 분포도 \n",
            " 0     799\n",
            "1     973\n",
            "2     985\n",
            "3     982\n",
            "4     963\n",
            "5     988\n",
            "6     975\n",
            "7     990\n",
            "8     996\n",
            "9     994\n",
            "10    999\n",
            "11    991\n",
            "12    984\n",
            "13    990\n",
            "14    987\n",
            "15    997\n",
            "16    910\n",
            "17    940\n",
            "18    775\n",
            "19    628\n",
            "dtype: int64\n",
            "target 클래스의 이름들 \n",
            " ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "target 클래스의 값은 0부터 19까지 20개로 구성돼있다.(target 값 0: alt.atheism, target 값 1: comp.graphics, ...)."
      ],
      "metadata": {
        "id": "QOpKOl6awcwC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(news_data.data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShU3qknzwr8Q",
        "outputId": "083f8972-5f3a-4000-c66f-5c87782ae5d4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From: egreen@east.sun.com (Ed Green - Pixel Cruncher)\n",
            "Subject: Re: Observation re: helmets\n",
            "Organization: Sun Microsystems, RTP, NC\n",
            "Lines: 21\n",
            "Distribution: world\n",
            "Reply-To: egreen@east.sun.com\n",
            "NNTP-Posting-Host: laser.east.sun.com\n",
            "\n",
            "In article 211353@mavenry.altcit.eskimo.com, maven@mavenry.altcit.eskimo.com (Norman Hamer) writes:\n",
            "> \n",
            "> The question for the day is re: passenger helmets, if you don't know for \n",
            ">certain who's gonna ride with you (like say you meet them at a .... church \n",
            ">meeting, yeah, that's the ticket)... What are some guidelines? Should I just \n",
            ">pick up another shoei in my size to have a backup helmet (XL), or should I \n",
            ">maybe get an inexpensive one of a smaller size to accomodate my likely \n",
            ">passenger? \n",
            "\n",
            "If your primary concern is protecting the passenger in the event of a\n",
            "crash, have him or her fitted for a helmet that is their size.  If your\n",
            "primary concern is complying with stupid helmet laws, carry a real big\n",
            "spare (you can put a big or small head in a big helmet, but not in a\n",
            "small one).\n",
            "\n",
            "---\n",
            "Ed Green, former Ninjaite |I was drinking last night with a biker,\n",
            "  Ed.Green@East.Sun.COM   |and I showed him a picture of you.  I said,\n",
            "DoD #0111  (919)460-8302  |\"Go on, get to know her, you'll like her!\"\n",
            " (The Grateful Dead) -->  |It seemed like the least I could do...\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "텍스트 데이터를 확인해보면 뉴스그룹 기사의 내용뿐만 아니라 뉴스그룹 제목, 작성자, 소속, 이메일 등의 다양한 정보를 가지고 있다. 이 중에서 내용을 제외하고 제목 등의 다른 정보는 제거한다.\n",
        "\n",
        "* 이유 : 제목과 소속, 이메일 주소 등의 헤더와 푸터 정보들은 뉴스그룹 분류의 target 클래스 값과 수야한 데이터를 가지고 있을 경우가 많기 때문이다. 이 피처들을 포함하게 되면 왠만한 ML 알고리즘을 적용해도 높은 성능을 나타낸다. 이것은 헤더와 푸터 정보를 포함하는 것은 텍스트 분석의 의도를 벗어난다. 그래서 순수한 텍스트만으로 구성된 기사 내용으로 어떤 뉴스그룹에 속하는지 분류하는 것이다."
      ],
      "metadata": {
        "id": "HXofUFBqwx15"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "# subset='train'으로 학습용 데이터만 추출, remove=('header', 'footers', 'quotes')로 내용만 추출\n",
        "train_news= fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'), random_state=156)\n",
        "X_train = train_news.data\n",
        "y_train = train_news.target\n",
        "\n",
        "# subset='test'으로 테스트(Test) 데이터만 추출, remove=('headers', 'footers', 'quotes')로 내용만 추출\n",
        "test_news= fetch_20newsgroups(subset='test',remove=('headers', 'footers','quotes'),random_state=156)\n",
        "X_test = test_news.data\n",
        "y_test = test_news.target\n",
        "\n",
        "print('학습 데이터 크기 {0} , 테스트 데이터 크기 {1}'.format(len(train_news.data) , len(test_news.data))) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XL4m7-V-xhyp",
        "outputId": "48b61390-f2f3-499c-9177-e1adc59caf22"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습 데이터 크기 11314 , 테스트 데이터 크기 7532\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 피처 벡터화 변환과 머신러닝 모델 학습/예측/평가\n",
        "\n",
        "학습 데이터는 11314개의 뉴스그룹 문서가 리스트 형태로 주어지고, 테스트 데이터는 7532개의 문서가 역시 리스트 형태로 주어졌다.\n",
        "\n",
        "* CountVectorizer를 이용해 학습 데이터의 텍스트를 피처 데이터화\n",
        "\n",
        "테스트 데이터에서 CountVectorizer를 적용할 때는 반드시 학습 데이터를 이용해 fit()이 수행된 CountVectorizer 객체를 이용해 테스트 데이터를 변환(transform)해야 한다. 그래야 학습 시 설정된 CountVectorizer의 피처 개수와 테스트 데이터를 CountVectorizer로 변환할 피처 개수가 같아진다. 테스트 데이터의 피처 벡터화는 학습 데이터에 사용된 CountVectorizer 객체 변수인 cnt_vect.transform()을 이용해 변환한다.\n",
        "\n",
        "테스트 데이터의 피처 벡터화 시 fit_transform()을 사용하면 안된다. CountVectorizer.fit_transform(테스트 데이터)을 테스트 데이터 세트에 적용하면 테스트 데이터 기반으로 다시 CountVectorizer가 fit() 수행하고 transform()하기 때문에 학습 시 사용된 피처 개수와 예측 시 사용할 피처 개수가 달라진다. "
      ],
      "metadata": {
        "id": "US353sReyAwB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Count Vectorization으로 feature extraction 변환 수행. \n",
        "cnt_vect = CountVectorizer()\n",
        "cnt_vect.fit(X_train)\n",
        "X_train_cnt_vect = cnt_vect.transform(X_train)\n",
        "\n",
        "# 학습 데이터로 fit( )된 CountVectorizer를 이용하여 테스트 데이터를 feature extraction 변환 수행. \n",
        "X_test_cnt_vect = cnt_vect.transform(X_test)\n",
        "\n",
        "print('학습 데이터 Text의 CountVectorizer Shape:',X_train_cnt_vect.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKLALchpA30W",
        "outputId": "4ab9ce74-5ba1-41aa-b7a4-20b7ea3095d1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습 데이터 Text의 CountVectorizer Shape: (11314, 101631)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습 데이터를 CountVectorizer로 피처를 추출한 결과 11314개의 문서에 피처, 즉 단어가 101631개로 만들어졌다."
      ],
      "metadata": {
        "id": "laRJ1BsBBhVv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# LogisticRegression을 이용하여 학습/예측/평가 수행. \n",
        "lr_clf = LogisticRegression(solver='lbfgs', max_iter=100)\n",
        "lr_clf.fit(X_train_cnt_vect , y_train)\n",
        "pred = lr_clf.predict(X_test_cnt_vect)\n",
        "print('CountVectorized Logistic Regression 의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test,pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmfLof8zCtQW",
        "outputId": "b093a89c-3023-466a-c5c8-b035f7de0abd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CountVectorized Logistic Regression 의 예측 정확도는 0.608\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Count 기반으로 피처 벡터화가 적용된 데이터 세트에 대한 로지스틱 회귀의 예측 정확도는 약 0.608이다. \n",
        "\n",
        "* Count 기반에서 TF-IDF 기반으로 벡터화를 변경하여 예측 모델 수행."
      ],
      "metadata": {
        "id": "Sf8J83DzDKS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# TF-IDF 벡터화를 적용해 학습 데이터 세트와 테스트 데이터 세트 변환\n",
        "tfidf_vect = TfidfVectorizer()\n",
        "tfidf_vect.fit(X_train)\n",
        "X_train_tfidf_vect = tfidf_vect.transform(X_train)\n",
        "X_test_tfidf_vect = tfidf_vect.transform(X_test)\n",
        "\n",
        "# LogisticRegression을 이용해 학습/예측/평가 수행\n",
        "lr_clf = LogisticRegression(solver='lbfgs', max_iter=100)\n",
        "lr_clf.fit(X_train_tfidf_vect, y_train)\n",
        "pred = lr_clf.predict(X_test_tfidf_vect)\n",
        "print('TF-IDF Logistic Regression 의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test ,pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xHWExCwDzoF",
        "outputId": "2ce95cde-56df-4dc2-aa2a-8497a3db7ade"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF Logistic Regression 의 예측 정확도는 0.674\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF가 단순 카운트 기반보다 훨씬 높은 예측 정확도를 제공한다. 일반적으로 문서 내에 텍스트가 많고 많은 문서를 가지는 텍스트 분석에서 카운트 벡터화보다는 TF-IDF 벡터화가 좋은 예측 결과를 도출한다.\n",
        "\n",
        "#### 텍스트 분석에서 머신러닝 모델의 성능을 향상지는 중요한 2가지 방법\n",
        "* 최적의 ML 알고리즘을 선택하는 것\n",
        "* 최상의 피처 전처리를 수행\n",
        "\n",
        "텍스트 정규화는 Count/TF-IDF 기반 피처 벡터화를 어떻게 효과적으로 적용했는지가 텍스트 기반의 머신러닝 성능에 큰 영향을 미칠 수 있다."
      ],
      "metadata": {
        "id": "7vlVuf84F7vd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF에 파라미터 적용\n",
        "# TfidfVectorizer 클래스의 스톱 워드를 기존 'None'에서 'english'로 변경, \n",
        "# ngram_range는 기존 (1,1)에서 (1,2)로, max_df=300으로 변경한 뒤 다시 예측 성능 측정\n",
        "tfidf_vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2), max_df=300 )\n",
        "tfidf_vect.fit(X_train)\n",
        "X_train_tfidf_vect = tfidf_vect.transform(X_train)\n",
        "X_test_tfidf_vect = tfidf_vect.transform(X_test)\n",
        "\n",
        "lr_clf = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
        "lr_clf.fit(X_train_tfidf_vect , y_train)\n",
        "pred = lr_clf.predict(X_test_tfidf_vect)\n",
        "print('TF-IDF Vectorized Logistic Regression 의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test ,pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHVeQqkcInIm",
        "outputId": "3ce65c33-6d10-4305-fe27-57b4d78d5b86"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF Vectorized Logistic Regression 의 예측 정확도는 0.692\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GridSearchCV를 이용해 로지스틱 회귀의 하이퍼 파라미터 최적화 수행.\n",
        "# 로지스틱 회귀의 C 파라미터만 변경하면서 최적의 C 값을 찾은 뒤 이 C값으로 학습된 모델에서 예측\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# 최적 C값 도출 튜닝 수행. CV는 3 폴드 세트로 설정\n",
        "params = {'C':[0.01, 0.1, 1, 5, 10]}\n",
        "grid_cv_lr = GridSearchCV(lr_clf, param_grid=params, cv=3, scoring='accuracy', verbose=1)\n",
        "grid_cv_lr.fit(X_train_tfidf_vect, y_train)\n",
        "print('Logistic Regression best C parameter :', grid_cv_lr.best_params_)\n",
        "\n",
        "# 최적 C 값으로 학습된 grid_cv로 예측 및 정확도 평가\n",
        "pred = grid_cv_lr.predict(X_test_tfidf_vect)\n",
        "print('TF-IDF Vectorized Logistic Regression 의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test ,pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NU7Y6Q0VJnnF",
        "outputId": "b6908efb-030f-4d3c-acde-9cbfdf071452"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
            "Logistic Regression best C parameter : {'C': 10}\n",
            "TF-IDF Vectorized Logistic Regression 의 예측 정확도는 0.701\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "로지스틱 회귀의 C가 10일 때 GridSearchCV의 교차 검증 테스트에서 가장 좋은 예측 성능을 나타냈고, 이를 테스트 데이터 세트에 적용해 약 0.701으로 이전보다 약간 향상된 성능 수치가 되었다."
      ],
      "metadata": {
        "id": "b9jHabSDKrit"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 사이킷런 파이프라인(Pipeline) 사용 및 GridSearchCV와의 결합\n",
        "\n",
        "* 사이킷런의 Pipeline 클래스 -> 피처 벡터화와 ML 알고리즘 학습/예측을 위한 코드 작성을 한번에 진행 가능\n",
        "\n",
        "        pipeline = Pipeline([('tfidf_vect', TfidfVectorizer(stop_words='english')),('lr_clf', LogisticRegression(random_state=156))])"
      ],
      "metadata": {
        "id": "4x0qSRwmLlG_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이것은 TfidfVectorizer 객체를 tfidf_vect라는 객체 변수명으로, LogisticRegression 객체를 lr_clf라는 객체 변수명으로 생성한 뒤 이 두 개의 객체를 파이프라인으로 연결하는 Pipeline 객체 Pipeline을 생성한다는 의미다."
      ],
      "metadata": {
        "id": "FcCMRa0-NZ6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# TfidfVectorizer 객체를 tfidf_vect로, LogisticRegression 객체를 lr_clf로 생성하는 Pipeline 생성\n",
        "pipeline = Pipeline([('tfidf_vect', TfidfVectorizer(stop_words='english', ngram_range=(1, 2), max_df=300)), ('lr_clf', LogisticRegression(C=10))])\n",
        "\n",
        "# 별도의 TfidfVectorizer 객체의 fit(), transform()과 LogisticRegression의 fit(), predict()가 필요없음\n",
        "# pipeline의 fit()과 predict()만으로 한꺼번에 피처 벡터화와 ML 학습/예측이 가능\n",
        "pipeline.fit(X_train, y_train)\n",
        "pred = pipeline.predict(X_test)\n",
        "print('Pipeline을 통한 Logistic Regression의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test, pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQoQhCdoM7qN",
        "outputId": "a3675f56-adee-4051-dec9-e9b8f2cc65ba"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline을 통한 Logistic Regression의 예측 정확도는 0.701\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "사이킷런은 GridSearchCV 클래스의 생성 파라미터로 Pipeline을 입력해 Pipeline 기반에서도 하이퍼 파라미터 튜닝을 GridSearchCV 방식으로 진행할 수 있게 지원한다. 이렇게 하면 피처 벡터화를 위한 파라미터와 ML 알고리즘의 하이퍼 파라미터를 모두 한번에 GridSearchCV를 이용해 최적화할 수 있다.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1ebifUBsO8Py"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GridSearchCV에 Pipeline을 입력하면서 TfidfVectorizer의 파라미터와 Logistic Regression의 하이퍼 파라미터를 함께 최적화한다. "
      ],
      "metadata": {
        "id": "ue0oGW1eSg8r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore') \n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf_vect', TfidfVectorizer(stop_words='english')),\n",
        "    ('lr_clf', LogisticRegression())\n",
        "])\n",
        " \n",
        "# Pipeline에 기술된 각각의 객체 변수에 언더바(_)2개를 연달아 붙여 GridSearchCV에 사용될 \n",
        "# 파라미터/하이퍼 파라미터 이름과 값을 설정. . \n",
        "params = { 'tfidf_vect__ngram_range': [(1,1), (1,2), (1,3)],\n",
        "           'tfidf_vect__max_df': [100, 300, 700],\n",
        "           'lr_clf__C': [1,5,10]\n",
        "}\n",
        "\n",
        "# GridSearchCV의 생성자에 Estimator가 아닌 Pipeline 객체 입력\n",
        "grid_cv_pipe = GridSearchCV(pipeline, param_grid=params, cv=3 , scoring='accuracy',verbose=1)\n",
        "grid_cv_pipe.fit(X_train , y_train)\n",
        "print(grid_cv_pipe.best_params_ , grid_cv_pipe.best_score_)\n",
        "\n",
        "pred = grid_cv_pipe.predict(X_test)\n",
        "print('Pipeline을 통한 Logistic Regression 의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test ,pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0NkVl9ZQe8k",
        "outputId": "677bb05a-27ae-4e84-e589-ecef70a21de2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
            "{'lr_clf__C': 10, 'tfidf_vect__max_df': 300, 'tfidf_vect__ngram_range': (1, 2)} 0.7536687914006531\n",
            "Pipeline을 통한 Logistic Regression 의 예측 정확도는 0.701\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TfidfVectorizer 객체의 max_df 파라미터가 700, ngram_range 파라미터가 (1, 2)로 피처 벡터화된 데이터 세트에 LogisticRegression의 C 하이퍼 파라미터에 10을 적용해 예측 분류를 수행할 때 가장 좋은 검증 세트 성능 수치가 도출되었다. 정확도는 약 0.702로 크게 개선되지 않아 아쉽다.\n",
        "\n"
      ],
      "metadata": {
        "id": "oWyGhkjbQdUs"
      }
    }
  ]
}