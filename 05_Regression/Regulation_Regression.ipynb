{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Regulation_Regression.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNibdw1BcDcu6GzkP1WbHC+"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiI3wWCXxnt1"
      },
      "source": [
        "# 규제 선형 모델\n",
        "\n",
        "비용함수는 학습 데이터의 잔차 오류값을 최소로하는 RSS 최소화 방법과 과적합 방지를 위해 회귀계수 값이 커지지 않도록 하는 방법이 균형을 이루어야 한다.\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAqJ77yJzxxN"
      },
      "source": [
        "* alpha : 학습 데이터 적합 정도와 회귀 계수 값의 크기 제어를 수행하는 튜닝 파라미터\n",
        "    * alpha = 0(또는 매우 작은 값) : Min(RSS(W) + 0) -> RSS 최소화 -> W값이 켜저도 어느 정도 상쇄 가능하여 적합 개선\n",
        "    * alpha = 무한대(또는 매우 큰 값) : Min(RSS(W) + alpha * ||W||2 -> W를 최소화(0 또는 매우 작은 값) -> 과적합 개선\n",
        "\n",
        "\n",
        "* 규제 : 비용함수에 alpha 값으로 패널티를 부여해 회귀 계수 값의 크기를 감소시켜 과적합을 개선하는 방식\n",
        "    * L2 규제 : alpha * ||W||2 (W 제곱에 패널티 부여) -> 릿지(Ridge) 회귀\n",
        "    * L1 규제 : alpha * ||W||1 (W 절대값에 패널티 부여) -> 라쏘(Lasso) 회귀(영향력이 크지 않은 회귀 계수 값을 0으로 변환)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqVBJbdY2c4E"
      },
      "source": [
        "# 릿지 회귀\n",
        "\n",
        "* Ridge 클래스의 주요 생성 파라미터 alpha : alpha L2 규제 계수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4JwnDy0tcFo",
        "outputId": "a30cb8b5-e8d6-4880-a634-8776bada0275"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "boston = load_boston()\n",
        "\n",
        "ridge = Ridge(alpha=10)\n",
        "neg_mse_scores = cross_val_score(ridge, boston.data, boston.target, scoring=\"neg_mean_squared_error\", cv=5)\n",
        "rmse_scores = np.sqrt(-1 * neg_mse_scores)\n",
        "avg_rmse = np.mean(rmse_scores)\n",
        "\n",
        "print('5 folds 의 개별 Negative MSE scores :', np.round(neg_mse_scores, 2))\n",
        "print('5 folds 의 개별 RMSE scores :', np.round(rmse_scores, 2))\n",
        "print('5 folds 의 평균 RMSE : {0:.3f}'.format(avg_rmse))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 folds 의 개별 Negative MSE scores : [-11.42 -24.29 -28.14 -74.6  -28.52]\n",
            "5 folds 의 개별 RMSE scores : [3.38 4.93 5.31 8.64 5.34]\n",
            "5 folds 의 평균 RMSE : 5.518\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
            "\n",
            "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
            "    the documentation of this function for further details.\n",
            "\n",
            "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
            "    dataset unless the purpose of the code is to study and educate about\n",
            "    ethical issues in data science and machine learning.\n",
            "\n",
            "    In this special case, you can fetch the dataset from the original\n",
            "    source::\n",
            "\n",
            "        import pandas as pd\n",
            "        import numpy as np\n",
            "\n",
            "\n",
            "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
            "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
            "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
            "        target = raw_df.values[1::2, 2]\n",
            "\n",
            "    Alternative datasets include the California housing dataset (i.e.\n",
            "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
            "    dataset. You can load the datasets as follows::\n",
            "\n",
            "        from sklearn.datasets import fetch_california_housing\n",
            "        housing = fetch_california_housing()\n",
            "\n",
            "    for the California housing dataset and::\n",
            "\n",
            "        from sklearn.datasets import fetch_openml\n",
            "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
            "\n",
            "    for the Ames housing dataset.\n",
            "    \n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7G85GFQ75MPz"
      },
      "source": [
        "릿지의 5개 폴드 세트의 평균 RMSE가 5.518로 LinearRegression의 RMSE 평균인 5.829보다 더 뛰어난 예측 성능을 보인다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIo1QyOg5W4y",
        "outputId": "2c9871f6-42b2-456a-f865-de8bf8cf80e3"
      },
      "source": [
        "# 릿지에 사용될 alpha 파라미터의 값을 정의\n",
        "alphas = [0, 0.1, 1, 10, 100]\n",
        "\n",
        "# alphas list 값을 반복하면서 alpha에 따른 평균 rmse 를 구함\n",
        "for alpha in alphas:\n",
        "    ridge = Ridge(alpha=alpha)\n",
        "\n",
        "    # cross_val_score를 이용해 5개의 폴드 평균 RMSE 계산\n",
        "    neg_mse_scores = cross_val_score(ridge, boston.data, boston.target, scoring=\"neg_mean_squared_error\", cv=5)\n",
        "    avg_rmse = np.mean(np.sqrt(-1 * neg_mse_scores))\n",
        "    print('alpha {0} 일 때 5 folds의 평균 RMSE : {1:.3f}'.format(alpha, avg_rmse))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alpha 0 일 때 5 folds의 평균 RMSE : 5.829\n",
            "alpha 0.1 일 때 5 folds의 평균 RMSE : 5.788\n",
            "alpha 1 일 때 5 folds의 평균 RMSE : 5.653\n",
            "alpha 10 일 때 5 folds의 평균 RMSE : 5.518\n",
            "alpha 100 일 때 5 folds의 평균 RMSE : 5.330\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lc4sAUhG6LgD"
      },
      "source": [
        "alpha가 100일 때 평균 RMSE가 5.330으로 가장 좋다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXpzpNYj9rAR",
        "outputId": "b4efc08e-b8b5-4e3b-b122-42530b51df63"
      },
      "source": [
        "boston = load_boston()\n",
        "bostonDF = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
        "bostonDF['PRICE'] = boston.target\n",
        "y_target = bostonDF['PRICE']\n",
        "X_data = bostonDF.drop(['PRICE'], axis=1, inplace=False)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
            "\n",
            "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
            "    the documentation of this function for further details.\n",
            "\n",
            "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
            "    dataset unless the purpose of the code is to study and educate about\n",
            "    ethical issues in data science and machine learning.\n",
            "\n",
            "    In this special case, you can fetch the dataset from the original\n",
            "    source::\n",
            "\n",
            "        import pandas as pd\n",
            "        import numpy as np\n",
            "\n",
            "\n",
            "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
            "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
            "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
            "        target = raw_df.values[1::2, 2]\n",
            "\n",
            "    Alternative datasets include the California housing dataset (i.e.\n",
            "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
            "    dataset. You can load the datasets as follows::\n",
            "\n",
            "        from sklearn.datasets import fetch_california_housing\n",
            "        housing = fetch_california_housing()\n",
            "\n",
            "    for the California housing dataset and::\n",
            "\n",
            "        from sklearn.datasets import fetch_openml\n",
            "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
            "\n",
            "    for the Ames housing dataset.\n",
            "    \n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "tiWFX9Qu6RQa",
        "outputId": "400a795c-19b8-432c-cdb7-699b93c63b33"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# 각 alpha에 따른 회귀 계수 값을 시각화 하기 위해 5개의 열로 된 맷플롯립 축 생성\n",
        "fig, ax = plt.subplots(figsize=(18, 6), nrows=1, ncols=5)\n",
        "# 각 alpha에 따른 회귀 계수 값을 데이터 저장하기 위한 DataFrame 생성\n",
        "coeff_df = pd.DataFrame()\n",
        "\n",
        "# alphas 리스트 값을 차례로 입력해 회귀 계수 값 시각화 및 데이터 저장. pos는 axis의 위치 지정\n",
        "for pos, alpha in enumerate(alphas):\n",
        "    ridge = Ridge(alpha=alpha)\n",
        "    ridge.fit(X_data, y_target)\n",
        "    # alpha에 따른 피처별로 회귀 계수를 Series로 변환하고 이를 DataFrame의 칼럼으로 추가\n",
        "    coeff = pd.Series(data=ridge.coef_, index=X_data.columns)\n",
        "    colname = 'alpha:'+str(alpha)\n",
        "    coeff_df[colname] = coeff\n",
        "    # 막대 그래프로 각 alpha 값에서의 회귀 계수를 시각화. 회귀 계수값이 높은 순으로 표현\n",
        "    coeff = coeff.sort_values(ascending=False)\n",
        "    ax[pos].set_title(colname)\n",
        "    ax[pos].set_xlim(-3, 6)\n",
        "    sns.barplot(x=coeff.values, y=coeff.index, ax=ax[pos])\n",
        "# for 문 바깥에서 맷플롯립의 show 호출 및 alpha에 따른 피처별 회귀 계수를 DataFrame으로 표시\n",
        "plt.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1296x432 with 5 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQuOFO_G-Oky"
      },
      "source": [
        "alpha값이 증가할수록 회귀 계수 값은 지속적으로 작아진다. 특히 NOX 피처의 경우 alpha 값이 증가될수록 회귀 계수가 크게 작아지고 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "X1Fp5hZU-ily",
        "outputId": "9261bfa6-9adb-4774-de39-e5bfbf128236"
      },
      "source": [
        "sort_column = 'alpha:'+str(alphas[0])\n",
        "coeff_df.sort_values(by=sort_column, ascending=False)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alpha:0</th>\n",
              "      <th>alpha:0.1</th>\n",
              "      <th>alpha:1</th>\n",
              "      <th>alpha:10</th>\n",
              "      <th>alpha:100</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>RM</th>\n",
              "      <td>3.809865</td>\n",
              "      <td>3.818233</td>\n",
              "      <td>3.854000</td>\n",
              "      <td>3.702272</td>\n",
              "      <td>2.334536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CHAS</th>\n",
              "      <td>2.686734</td>\n",
              "      <td>2.670019</td>\n",
              "      <td>2.552393</td>\n",
              "      <td>1.952021</td>\n",
              "      <td>0.638335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RAD</th>\n",
              "      <td>0.306049</td>\n",
              "      <td>0.303515</td>\n",
              "      <td>0.290142</td>\n",
              "      <td>0.279596</td>\n",
              "      <td>0.315358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ZN</th>\n",
              "      <td>0.046420</td>\n",
              "      <td>0.046572</td>\n",
              "      <td>0.047443</td>\n",
              "      <td>0.049579</td>\n",
              "      <td>0.054496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>INDUS</th>\n",
              "      <td>0.020559</td>\n",
              "      <td>0.015999</td>\n",
              "      <td>-0.008805</td>\n",
              "      <td>-0.042962</td>\n",
              "      <td>-0.052826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B</th>\n",
              "      <td>0.009312</td>\n",
              "      <td>0.009368</td>\n",
              "      <td>0.009673</td>\n",
              "      <td>0.010037</td>\n",
              "      <td>0.009393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AGE</th>\n",
              "      <td>0.000692</td>\n",
              "      <td>-0.000269</td>\n",
              "      <td>-0.005415</td>\n",
              "      <td>-0.010707</td>\n",
              "      <td>0.001212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TAX</th>\n",
              "      <td>-0.012335</td>\n",
              "      <td>-0.012421</td>\n",
              "      <td>-0.012912</td>\n",
              "      <td>-0.013993</td>\n",
              "      <td>-0.015856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CRIM</th>\n",
              "      <td>-0.108011</td>\n",
              "      <td>-0.107474</td>\n",
              "      <td>-0.104595</td>\n",
              "      <td>-0.101435</td>\n",
              "      <td>-0.102202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LSTAT</th>\n",
              "      <td>-0.524758</td>\n",
              "      <td>-0.525966</td>\n",
              "      <td>-0.533343</td>\n",
              "      <td>-0.559366</td>\n",
              "      <td>-0.660764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PTRATIO</th>\n",
              "      <td>-0.952747</td>\n",
              "      <td>-0.940759</td>\n",
              "      <td>-0.876074</td>\n",
              "      <td>-0.797945</td>\n",
              "      <td>-0.829218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DIS</th>\n",
              "      <td>-1.475567</td>\n",
              "      <td>-1.459626</td>\n",
              "      <td>-1.372654</td>\n",
              "      <td>-1.248808</td>\n",
              "      <td>-1.153390</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NOX</th>\n",
              "      <td>-17.766611</td>\n",
              "      <td>-16.684645</td>\n",
              "      <td>-10.777015</td>\n",
              "      <td>-2.371619</td>\n",
              "      <td>-0.262847</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           alpha:0  alpha:0.1    alpha:1  alpha:10  alpha:100\n",
              "RM        3.809865   3.818233   3.854000  3.702272   2.334536\n",
              "CHAS      2.686734   2.670019   2.552393  1.952021   0.638335\n",
              "RAD       0.306049   0.303515   0.290142  0.279596   0.315358\n",
              "ZN        0.046420   0.046572   0.047443  0.049579   0.054496\n",
              "INDUS     0.020559   0.015999  -0.008805 -0.042962  -0.052826\n",
              "B         0.009312   0.009368   0.009673  0.010037   0.009393\n",
              "AGE       0.000692  -0.000269  -0.005415 -0.010707   0.001212\n",
              "TAX      -0.012335  -0.012421  -0.012912 -0.013993  -0.015856\n",
              "CRIM     -0.108011  -0.107474  -0.104595 -0.101435  -0.102202\n",
              "LSTAT    -0.524758  -0.525966  -0.533343 -0.559366  -0.660764\n",
              "PTRATIO  -0.952747  -0.940759  -0.876074 -0.797945  -0.829218\n",
              "DIS      -1.475567  -1.459626  -1.372654 -1.248808  -1.153390\n",
              "NOX     -17.766611 -16.684645 -10.777015 -2.371619  -0.262847"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qUlY2Ir1nMz"
      },
      "source": [
        "# 라쏘 회귀\n",
        "\n",
        "W의 절대값에 패널티를 부여하는 L1 규제를 선형 회귀에 적용한 것이 라쏘 회귀이다.\n",
        "\n",
        "즉 L1 규제는 alpha * ||W||1를 의미하며, 라쏘 회귀 비용함수의 목표는 RSS(W) + alpha * ||W||1 식을 최소화하는 W를 찾는 것이다.\n",
        "\n",
        "L1 규제는 불필요한 회귀 계수를 급격하게 감소시켜 0으로 만들고 제거 => 적절만 피쳐만 회귀에 포함시키는 피처 선택의 특정을 가지고 있다.\n",
        "\n",
        "* 파라미터 : alpha -> L1 규제 계수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uy2EwipN2qEa"
      },
      "source": [
        "from sklearn.linear_model import Lasso, ElasticNet\n",
        "\n",
        "# alpha 값에 따른 회귀 모델의 폴드 평균 RMSE를 출력하고 회귀 계수값들을 DataFrame으로 반환\n",
        "def get_linear_reg_eval(model_name, params=None, X_data_n=None, y_target_n=None, verbose=True, return_coeff=True):\n",
        "    coeff_df = pd.DataFrame()\n",
        "    if verbose:\n",
        "        print('###### ', model_name, '######')\n",
        "    for param in params:\n",
        "        if model_name == \"Ridge\": model = Ridge(alpha=param)\n",
        "        elif model_name == \"Lasso\": model = Lasso(alpha=param)\n",
        "        elif model_name == \"ElasticNet\": model = ElasticNet(alpha=param, l1_ratio=0.7)\n",
        "        neg_mse_scores = cross_val_score(model, X_data_n, y_target_n, scoring=\"neg_mean_squared_error\", cv=5)\n",
        "        avg_rmse = np.mean(np.sqrt(-1 * neg_mse_scores))\n",
        "        print('alpha {0}일 때 5 폴드 세트의 평균 RMSE : {1:.3f}'.format(param, avg_rmse))\n",
        "        # cross_val_score는 evaluation metric 만 반환하므로 모델을 다시 학습하여 회귀 계수 추출\n",
        "\n",
        "        model.fit(X_data_n, y_target_n)\n",
        "        if return_coeff:\n",
        "            # alpha에 따른 피처별 회귀 계수를 Series로 변환하고 이를 DataFrame의 칼럼으로 추가\n",
        "            coeff = pd.Series(data=model.coef_, index=X_data_n.columns)\n",
        "            colname = 'alpha:'+str(param)\n",
        "            coeff_df[colname]=coeff\n",
        "    return coeff_df\n",
        "# end of get_linear_regre_eval"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJrzGAv84Y7_"
      },
      "source": [
        "alpha값은 [0.07, 0.1, 0.5, 1, 3]로 입력. get_linear_reg_eval()에 모델명을 'Lasso'로 입력하면 라쏘 모델 기반으로 수행."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVBSPZG74Xlh",
        "outputId": "b066040a-0ce9-470b-a26e-f758f725a0f7"
      },
      "source": [
        "# 라쏘에 사용될 alpha 파라미터의 값을 정의하고 get_linear_reg_eval() 함수 호출\n",
        "lasso_alphas = [0.07, 0.1, 0.5, 1, 3]\n",
        "coeff_lasso_df = get_linear_reg_eval('Lasso', params=lasso_alphas, X_data_n=X_data, y_target_n=y_target)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "######  Lasso ######\n",
            "alpha 0.07일 때 5 폴드 세트의 평균 RMSE : 5.612\n",
            "alpha 0.1일 때 5 폴드 세트의 평균 RMSE : 5.615\n",
            "alpha 0.5일 때 5 폴드 세트의 평균 RMSE : 5.669\n",
            "alpha 1일 때 5 폴드 세트의 평균 RMSE : 5.776\n",
            "alpha 3일 때 5 폴드 세트의 평균 RMSE : 6.189\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8PQquGj5bCR"
      },
      "source": [
        "alpha가 0.07일 때 5.612로 가장 좋은 평균 RMSE를 보인다. 릿지 평균 5.518보다는 약간 떨어지는 수치지만, LinearRegression 평균인 5.829보다는 향상되었다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "_-ezvYL86N0B",
        "outputId": "8a0b13ff-32f1-4804-aba9-6803169b03eb"
      },
      "source": [
        "# 반환된 coeff_lasso_df를 첫 번째 칼럼순으로 내림차순 정렬해 회귀꼐수 DataFrame 출력\n",
        "sort_column = 'alpha:'+str(lasso_alphas[0])\n",
        "coeff_lasso_df.sort_values(by=sort_column, ascending=False)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alpha:0.07</th>\n",
              "      <th>alpha:0.1</th>\n",
              "      <th>alpha:0.5</th>\n",
              "      <th>alpha:1</th>\n",
              "      <th>alpha:3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>RM</th>\n",
              "      <td>3.789725</td>\n",
              "      <td>3.703202</td>\n",
              "      <td>2.498212</td>\n",
              "      <td>0.949811</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CHAS</th>\n",
              "      <td>1.434343</td>\n",
              "      <td>0.955190</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RAD</th>\n",
              "      <td>0.270936</td>\n",
              "      <td>0.274707</td>\n",
              "      <td>0.277451</td>\n",
              "      <td>0.264206</td>\n",
              "      <td>0.061864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ZN</th>\n",
              "      <td>0.049059</td>\n",
              "      <td>0.049211</td>\n",
              "      <td>0.049544</td>\n",
              "      <td>0.049165</td>\n",
              "      <td>0.037231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B</th>\n",
              "      <td>0.010248</td>\n",
              "      <td>0.010249</td>\n",
              "      <td>0.009469</td>\n",
              "      <td>0.008247</td>\n",
              "      <td>0.006510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NOX</th>\n",
              "      <td>-0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AGE</th>\n",
              "      <td>-0.011706</td>\n",
              "      <td>-0.010037</td>\n",
              "      <td>0.003604</td>\n",
              "      <td>0.020910</td>\n",
              "      <td>0.042495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TAX</th>\n",
              "      <td>-0.014290</td>\n",
              "      <td>-0.014570</td>\n",
              "      <td>-0.015442</td>\n",
              "      <td>-0.015212</td>\n",
              "      <td>-0.008602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>INDUS</th>\n",
              "      <td>-0.042120</td>\n",
              "      <td>-0.036619</td>\n",
              "      <td>-0.005253</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CRIM</th>\n",
              "      <td>-0.098193</td>\n",
              "      <td>-0.097894</td>\n",
              "      <td>-0.083289</td>\n",
              "      <td>-0.063437</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LSTAT</th>\n",
              "      <td>-0.560431</td>\n",
              "      <td>-0.568769</td>\n",
              "      <td>-0.656290</td>\n",
              "      <td>-0.761115</td>\n",
              "      <td>-0.807679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PTRATIO</th>\n",
              "      <td>-0.765107</td>\n",
              "      <td>-0.770654</td>\n",
              "      <td>-0.758752</td>\n",
              "      <td>-0.722966</td>\n",
              "      <td>-0.265072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DIS</th>\n",
              "      <td>-1.176583</td>\n",
              "      <td>-1.160538</td>\n",
              "      <td>-0.936605</td>\n",
              "      <td>-0.668790</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         alpha:0.07  alpha:0.1  alpha:0.5   alpha:1   alpha:3\n",
              "RM         3.789725   3.703202   2.498212  0.949811  0.000000\n",
              "CHAS       1.434343   0.955190   0.000000  0.000000  0.000000\n",
              "RAD        0.270936   0.274707   0.277451  0.264206  0.061864\n",
              "ZN         0.049059   0.049211   0.049544  0.049165  0.037231\n",
              "B          0.010248   0.010249   0.009469  0.008247  0.006510\n",
              "NOX       -0.000000  -0.000000  -0.000000 -0.000000  0.000000\n",
              "AGE       -0.011706  -0.010037   0.003604  0.020910  0.042495\n",
              "TAX       -0.014290  -0.014570  -0.015442 -0.015212 -0.008602\n",
              "INDUS     -0.042120  -0.036619  -0.005253 -0.000000 -0.000000\n",
              "CRIM      -0.098193  -0.097894  -0.083289 -0.063437 -0.000000\n",
              "LSTAT     -0.560431  -0.568769  -0.656290 -0.761115 -0.807679\n",
              "PTRATIO   -0.765107  -0.770654  -0.758752 -0.722966 -0.265072\n",
              "DIS       -1.176583  -1.160538  -0.936605 -0.668790 -0.000000"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHF58Wi_6hPA"
      },
      "source": [
        "alpha의 크기가 증가함에 따라 일부 피처의 회귀 계수가 0으로 바뀌는 것을 볼 수 있다. \n",
        "\n",
        "NOX의 경우 처음부터 회귀 계수가 0이고, INDUS, CHAS와 같은 속성의 회귀 계수는 alpha를 증가시키면서 0으로 바뀐다. 회귀 계수가 0인 피처는 회귀 식에서 제외되면서 피처 선택의 효과를 얻을 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLRH7mqn6925"
      },
      "source": [
        "# 엘라스틱넷 회귀\n",
        "\n",
        "* L1 규제와 L2 규제를 결합한 회귀\n",
        "    * 엘라스틱넷 회귀의 목표는 RSS(W) + alpha2 * ||W||^2 + alpha1 * ||W||1 식을 최소화하는 W를 찾는 것.\n",
        "\n",
        "엘라스틱넷은 라쏘 회귀가 서로 상관관계가 높은 피처들의 경우에 이들 중에서 중요 피처만을 셀렉션하고 다른 피처들은 모두 회귀 계수를 0으로 만드는 성향을 가져, alpha 값에 따라 회귀 계수의 값이 급격히 변동할 수 있다는 단점을 완화하기 위해 라쏘 회귀를 추가한 것.\n",
        "\n",
        "* L1과 L2 규제가 결합된 규제로 수행 시간이 상대적으로 오래 걸린다.\n",
        "* 파라미터 : alpha와 l1_ratio\n",
        "    * 엘라스틱넷의 규제 = a * L1 + b * L2\n",
        "    * alpha = a+b => a = L1 규제의 alpha 값 / b = L2 규제의 alpha 값\n",
        "    * l1_ratio = a / (a + b), l1_ratio가 0이면 a가 0이므로 L2규제와 동일, l1_ratio가 1이면 b가 0이므로 L1 규제와 동일"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-h4odxp6hAp",
        "outputId": "a83ad783-1887-4aee-acd8-6bb518872017"
      },
      "source": [
        "# 엘라스틱넷에 사용될 alpha 파라미터의 값들을 정의하고 get_linear_reg_eval() 함수 호출\n",
        "# l1_ratio는 0.7로 고정 (model = ElasticNet(alpha=param, l1_ratio=0.7))\n",
        "elastic_alphas = [0.07, 0.1, 0.5, 1, 3]\n",
        "coeff_elastic_df = get_linear_reg_eval('ElasticNet', params=elastic_alphas, X_data_n=X_data, y_target_n=y_target)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "######  ElasticNet ######\n",
            "alpha 0.07일 때 5 폴드 세트의 평균 RMSE : 5.542\n",
            "alpha 0.1일 때 5 폴드 세트의 평균 RMSE : 5.526\n",
            "alpha 0.5일 때 5 폴드 세트의 평균 RMSE : 5.467\n",
            "alpha 1일 때 5 폴드 세트의 평균 RMSE : 5.597\n",
            "alpha 3일 때 5 폴드 세트의 평균 RMSE : 6.068\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "GbxHt-v6-l6f",
        "outputId": "c2ad330b-8595-4316-ce1b-03e2b5bf0fcd"
      },
      "source": [
        "# 반호나된 coeff_elastic_df를 첫 번째 칼럼순으로 내림차순 정렬해 회귀계수 DataFrame 출력\n",
        "sort_column = 'alpha:'+str(elastic_alphas[0])\n",
        "coeff_elastic_df.sort_values(by=sort_column, ascending=False)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alpha:0.07</th>\n",
              "      <th>alpha:0.1</th>\n",
              "      <th>alpha:0.5</th>\n",
              "      <th>alpha:1</th>\n",
              "      <th>alpha:3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>RM</th>\n",
              "      <td>3.574162</td>\n",
              "      <td>3.414154</td>\n",
              "      <td>1.918419</td>\n",
              "      <td>0.938789</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CHAS</th>\n",
              "      <td>1.330724</td>\n",
              "      <td>0.979706</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RAD</th>\n",
              "      <td>0.278880</td>\n",
              "      <td>0.283443</td>\n",
              "      <td>0.300761</td>\n",
              "      <td>0.289299</td>\n",
              "      <td>0.146846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ZN</th>\n",
              "      <td>0.050107</td>\n",
              "      <td>0.050617</td>\n",
              "      <td>0.052878</td>\n",
              "      <td>0.052136</td>\n",
              "      <td>0.038268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B</th>\n",
              "      <td>0.010122</td>\n",
              "      <td>0.010067</td>\n",
              "      <td>0.009114</td>\n",
              "      <td>0.008320</td>\n",
              "      <td>0.007020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AGE</th>\n",
              "      <td>-0.010116</td>\n",
              "      <td>-0.008276</td>\n",
              "      <td>0.007760</td>\n",
              "      <td>0.020348</td>\n",
              "      <td>0.043446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TAX</th>\n",
              "      <td>-0.014522</td>\n",
              "      <td>-0.014814</td>\n",
              "      <td>-0.016046</td>\n",
              "      <td>-0.016218</td>\n",
              "      <td>-0.011417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>INDUS</th>\n",
              "      <td>-0.044855</td>\n",
              "      <td>-0.042719</td>\n",
              "      <td>-0.023252</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CRIM</th>\n",
              "      <td>-0.099468</td>\n",
              "      <td>-0.099213</td>\n",
              "      <td>-0.089070</td>\n",
              "      <td>-0.073577</td>\n",
              "      <td>-0.019058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NOX</th>\n",
              "      <td>-0.175072</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LSTAT</th>\n",
              "      <td>-0.574822</td>\n",
              "      <td>-0.587702</td>\n",
              "      <td>-0.693861</td>\n",
              "      <td>-0.760457</td>\n",
              "      <td>-0.800368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PTRATIO</th>\n",
              "      <td>-0.779498</td>\n",
              "      <td>-0.784725</td>\n",
              "      <td>-0.790969</td>\n",
              "      <td>-0.738672</td>\n",
              "      <td>-0.423065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DIS</th>\n",
              "      <td>-1.189438</td>\n",
              "      <td>-1.173647</td>\n",
              "      <td>-0.975902</td>\n",
              "      <td>-0.725174</td>\n",
              "      <td>-0.031208</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         alpha:0.07  alpha:0.1  alpha:0.5   alpha:1   alpha:3\n",
              "RM         3.574162   3.414154   1.918419  0.938789  0.000000\n",
              "CHAS       1.330724   0.979706   0.000000  0.000000  0.000000\n",
              "RAD        0.278880   0.283443   0.300761  0.289299  0.146846\n",
              "ZN         0.050107   0.050617   0.052878  0.052136  0.038268\n",
              "B          0.010122   0.010067   0.009114  0.008320  0.007020\n",
              "AGE       -0.010116  -0.008276   0.007760  0.020348  0.043446\n",
              "TAX       -0.014522  -0.014814  -0.016046 -0.016218 -0.011417\n",
              "INDUS     -0.044855  -0.042719  -0.023252 -0.000000 -0.000000\n",
              "CRIM      -0.099468  -0.099213  -0.089070 -0.073577 -0.019058\n",
              "NOX       -0.175072  -0.000000  -0.000000 -0.000000 -0.000000\n",
              "LSTAT     -0.574822  -0.587702  -0.693861 -0.760457 -0.800368\n",
              "PTRATIO   -0.779498  -0.784725  -0.790969 -0.738672 -0.423065\n",
              "DIS       -1.189438  -1.173647  -0.975902 -0.725174 -0.031208"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bY6Pidx-lhH"
      },
      "source": [
        "alpha 0.5일 때 RMSE가 5.467로 가장 좋은 예측 성능을 보이고 있다. alpha 값에 따른 피처들의 회귀 계수들 값이 라쏘보다는 상대적으로 0이 되는 값이 적은 것을 알 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HLMr-Xm_WCH"
      },
      "source": [
        "# 선형 회귀 모델을 위한 데이터 변환\n",
        "\n",
        "* 피처와 타깃값 간에 선형 관계 가정\n",
        "* 피처값과 타깃값의 분포가 정규 분포를 따른다고 가정 -> 데이터가 심하게 왜곡되었을 경우, 스케일링 및 정규화 수행 필요\n",
        "\n",
        "1. StandardScaler 클래스를 이용해 평균이 0, 분산이 1인 표준 평균 분포를 가진 데이터 세트로 변환 또는 MinMaxScaler 클래스를 이용해 최솟값이 0이고 최댓값이 1인 값으로 정규화 => 예측 성능 향상 기대하기 어려움\n",
        "\n",
        "2. 1을 수행한 후 예측 성능 향상이 없을 경우, 스케일링/정규화를 수행한 데이터 세트에 다항 특성을 적용하여 변환 => 과적합 문제 발생 가능\n",
        "\n",
        "3. log 함수를 적용한 로그 변환. 정규 분포에 가까운 형태로 값이 분포된다. 가장 많이 사용되는 방법."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiQ_TC_o8q7m"
      },
      "source": [
        "# method는 표준 정규 분포 변환(Standard), 최댓값/최솟값 정규화(MinMax), 로그 변환(Log) 결정\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "# p_degree는 다항식 특성을 추가할 때 적용, p_degree는 2이상 부여하지 않는다\n",
        "def get_scaled_data(method='None', p_degree=None, input_data=None):\n",
        "    if method == 'Standard':\n",
        "        scaled_data = StandardScaler().fit_transform(input_data)\n",
        "    elif method == 'MinMax':\n",
        "        scaled_data = MinMaxScaler().fit_transform(input_data)\n",
        "    elif method == 'Log':\n",
        "        scaled_data = np.log1p(input_data)\n",
        "    else:\n",
        "        scaled_data = input_data\n",
        "    \n",
        "    if p_degree != None:\n",
        "        scaled_data = PolynomialFeatures(degree=p_degree, include_bias=False).fit_transform(scaled_data)\n",
        "    return scaled_data"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YZ8qSSZ-2B-",
        "outputId": "c0b77eaa-fa95-4358-ac74-0eab316a1178"
      },
      "source": [
        "# Ridge의 alpha 값을 다르게 적용하고 다양한 데이터 변환 방법에 따른 RMSE 추출\n",
        "alpha = [0.1, 1, 10, 100]\n",
        "\n",
        "# 5개의 방식으로 변환, 먼저 원본 그대로, 표준정규 분포, 표준정규 분포 + 다항 특성\n",
        "# 최대/최소 정규화, 최대/최소 정규화 + 다항 특성, 로그 변환\n",
        "scale_methods=[(None, None), ('Standard', None), ('Standard', 2), \n",
        "               ('MinMax', None), ('MinMax', 2), ('Log', None)]\n",
        "for scale_method in scale_methods:\n",
        "    x_data_scaled = get_scaled_data(method=scale_method[0], p_degree=scale_method[1], input_data=X_data)\n",
        "    print('\\n## 변환 유형:{0}, Polynomial Degree:{1}'.format(scale_method[0], scale_method[1]))\n",
        "    get_linear_reg_eval('Ridge', params=alphas, X_data_n=x_data_scaled, y_target_n=y_target, verbose=False, return_coeff=False)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "## 변환 유형:None, Polynomial Degree:None\n",
            "alpha 0일 때 5 폴드 세트의 평균 RMSE : 5.829\n",
            "alpha 0.1일 때 5 폴드 세트의 평균 RMSE : 5.788\n",
            "alpha 1일 때 5 폴드 세트의 평균 RMSE : 5.653\n",
            "alpha 10일 때 5 폴드 세트의 평균 RMSE : 5.518\n",
            "alpha 100일 때 5 폴드 세트의 평균 RMSE : 5.330\n",
            "\n",
            "## 변환 유형:Standard, Polynomial Degree:None\n",
            "alpha 0일 때 5 폴드 세트의 평균 RMSE : 5.829\n",
            "alpha 0.1일 때 5 폴드 세트의 평균 RMSE : 5.826\n",
            "alpha 1일 때 5 폴드 세트의 평균 RMSE : 5.803\n",
            "alpha 10일 때 5 폴드 세트의 평균 RMSE : 5.637\n",
            "alpha 100일 때 5 폴드 세트의 평균 RMSE : 5.421\n",
            "\n",
            "## 변환 유형:Standard, Polynomial Degree:2\n",
            "alpha 0일 때 5 폴드 세트의 평균 RMSE : 160800958734322.594\n",
            "alpha 0.1일 때 5 폴드 세트의 평균 RMSE : 8.827\n",
            "alpha 1일 때 5 폴드 세트의 평균 RMSE : 6.871\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:156: LinAlgWarning: Ill-conditioned matrix (rcond=1.14452e-17): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:156: LinAlgWarning: Ill-conditioned matrix (rcond=8.44328e-17): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:156: LinAlgWarning: Ill-conditioned matrix (rcond=2.54163e-17): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alpha 10일 때 5 폴드 세트의 평균 RMSE : 5.485\n",
            "alpha 100일 때 5 폴드 세트의 평균 RMSE : 4.634\n",
            "\n",
            "## 변환 유형:MinMax, Polynomial Degree:None\n",
            "alpha 0일 때 5 폴드 세트의 평균 RMSE : 5.829\n",
            "alpha 0.1일 때 5 폴드 세트의 평균 RMSE : 5.764\n",
            "alpha 1일 때 5 폴드 세트의 평균 RMSE : 5.465\n",
            "alpha 10일 때 5 폴드 세트의 평균 RMSE : 5.754\n",
            "alpha 100일 때 5 폴드 세트의 평균 RMSE : 7.635\n",
            "\n",
            "## 변환 유형:MinMax, Polynomial Degree:2\n",
            "alpha 0일 때 5 폴드 세트의 평균 RMSE : 17022199435545.172\n",
            "alpha 0.1일 때 5 폴드 세트의 평균 RMSE : 5.298\n",
            "alpha 1일 때 5 폴드 세트의 평균 RMSE : 4.323\n",
            "alpha 10일 때 5 폴드 세트의 평균 RMSE : 5.185\n",
            "alpha 100일 때 5 폴드 세트의 평균 RMSE : 6.538\n",
            "\n",
            "## 변환 유형:Log, Polynomial Degree:None\n",
            "alpha 0일 때 5 폴드 세트의 평균 RMSE : 4.829\n",
            "alpha 0.1일 때 5 폴드 세트의 평균 RMSE : 4.770\n",
            "alpha 1일 때 5 폴드 세트의 평균 RMSE : 4.676\n",
            "alpha 10일 때 5 폴드 세트의 평균 RMSE : 4.836\n",
            "alpha 100일 때 5 폴드 세트의 평균 RMSE : 6.241\n"
          ]
        }
      ]
    }
  ]
}